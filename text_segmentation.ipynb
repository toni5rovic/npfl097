{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ad156f9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265dd22",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d9181a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TributespouredinfromaroundtheworldThursdaytothelateLabourPartyleaderJohnSmith,whodiedearlierfromamassiveheartattackaged55.InWashington,theUSStateDepartmentissuedastatementregretting\"theuntimelydeath\"oftherapier-tonguedScottishbarristerandparliamentarian.\"Mr.Smith,throughouthisdistinguishedcareeringovernmentandinopposition,leftaprofoundimpressiononthehistoryofhispartyandhiscountry,\"StateDepartmentspokesmanMichaelMcCurrysaid.\"Secretary(ofStateWarren)ChristopherextendshisdeepestcondolencestoMrs.SmithandtotheSmithchildren.\"InBonn,theheadoftheGermanSocialDemocraticParty,RudolfScharping,saidinastatementhewas\"veryaffectedbythesuddendeathofJohnSmith.\"AgoodfriendofGermansocialdemocracyhasleftustooearly.Hewasveryclosetoachievinghislife'sgoalofmakingtheLabourPartythelargestpoliticalforceinBritain\"andwouldbe\"cruellymissed\"inEurope,hesaid.HongKongGovernorChrisPatten,aformerConservativePartychairman,offeredhiscondolencestotheSmithfamilyandsaidhisformerpolitcalopponentwasa\"goodanddecentman,widelyresp\n"
     ]
    }
   ],
   "source": [
    "with open('data/data_small.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d7344e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652297"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_size = len(text)\n",
    "text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "0a6e917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "20c3df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 74\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique characters: {}\".format(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d8729",
   "metadata": {},
   "source": [
    "- There is 2 ð‘›âˆ’1 possible segmentations for ð‘›-characters long data.\n",
    "- ð‘› âˆ’ 1 latent binary variables $ð‘ _ð‘–$: denoting whether there is of isnâ€™t a separator between two characters.\n",
    "- Collapsed Gibbs sampling. Sample one variable conditioned by all the others.\n",
    "- Exchangeability: if we reorder the words in the sequence, overall probability is the same.\n",
    "- We can virtually move the changed words at the end of the sequence, compute the overal probablility of the two possibilities and then move the words virtually back.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53741b",
   "metadata": {},
   "source": [
    "if $s_i$ is 1, then there is a separator between characters $c_i$ and $c_{i+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "93b6384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the random seeds\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c569a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def segmentation(text, text_size, s):\n",
    "    words = []\n",
    "    current_word = \"\"\n",
    "    for idx, character in enumerate(text):\n",
    "        if idx == text_size - 1:\n",
    "            current_word += character\n",
    "            continue\n",
    "        \n",
    "        if s[idx] == 1:\n",
    "            current_word += character\n",
    "            words.append(current_word)\n",
    "            current_word = \"\"\n",
    "        else:\n",
    "            current_word += character\n",
    "    return words\n",
    "\n",
    "def get_word_counts(words):\n",
    "    count = {}\n",
    "    counter = collections.Counter(words)\n",
    "    return counter\n",
    "    for key, value in counter.items():\n",
    "        count[key] = value\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1e93bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_word(text, s, i):\n",
    "    word = \"\"\n",
    "    start_idx = i - 1\n",
    "    if s[start_idx] == 1:\n",
    "        start_idx -= 1\n",
    "    while start_idx >= 0:\n",
    "        if s[start_idx] == 1:\n",
    "            break\n",
    "        start_idx -= 1\n",
    "    \n",
    "    word = text[start_idx+1:i]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "230a51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(text, s, i):\n",
    "    word = \"\"\n",
    "    end_idx = i + 1\n",
    "    while end_idx < len(text) - 1:\n",
    "        if s[end_idx] == 1:\n",
    "            break\n",
    "        end_idx += 1\n",
    "    \n",
    "    word = text[i:end_idx + 1]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5c3f013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p0(word, p_c):\n",
    "    uniform = 1.0 / float(C)\n",
    "    return uniform**len(word) * p_c**(len(word)-1) * (1 - p_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b8e31103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(count_dict, word):\n",
    "    if word not in count_dict:\n",
    "        count_dict[word] = 0\n",
    "    \n",
    "    count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "1ba35ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrement(count_dict, word):\n",
    "    if word not in count_dict:\n",
    "        count_dict[word] = 1\n",
    "    \n",
    "    count_dict[word] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "249a2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRP_TextSegmentation(text, text_size, iterations, alpha, p_c, p_cont):\n",
    "    s = np.random.randint(low=0, high=2, size=text_size-1)\n",
    "    words = segmentation(text, text_size, s)\n",
    "    count = get_word_counts(words)\n",
    "    t = sum(count.values())\n",
    "    \n",
    "    opsa_progress_bar = tqdm(range(1, text_size - 1), desc=\"Text processing\")\n",
    "    \n",
    "    for iteration in tqdm(range(iterations), desc=\"Iterations\"):\n",
    "        opsa_progress_bar.reset()\n",
    "        for i in np.random.permutation(range(1, text_size - 1)):\n",
    "            \n",
    "            prev_word = get_prev_word(text, s, i)\n",
    "            next_word = get_next_word(text, s, i)\n",
    "            \n",
    "            joined = prev_word + next_word\n",
    "            if s[i] == 0:\n",
    "                count[joined] -= 1\n",
    "                count[joined] = max(0, count[joined])\n",
    "                t -= 1\n",
    "            else:\n",
    "                count[prev_word] -= 1\n",
    "                count[prev_word] = max(0, count[prev_word])\n",
    "                count[next_word] -= 1\n",
    "                count[next_word] = max(0, count[next_word])\n",
    "                t -= 2\n",
    "            \n",
    "            p_0 = (alpha * p0(joined, p_c) + count[joined]) / (alpha + t)\n",
    "            p_1 = (alpha * p0(prev_word, p_c) + count[prev_word]) / (alpha + t)\n",
    "            p_1 *= (alpha * p0(next_word, p_c) + count[next_word]) / (alpha + t + 1)\n",
    "            p_1 *= p_cont\n",
    "            \n",
    "            #s[i] = sample 0 or 1 with weights p[0] and p[1]\n",
    "            #s[i] = np.random.choice([0, 1], p=[p_0, p_1])\n",
    "            if (random.random() * (p_0 + p_1)) < p_1:\n",
    "                s[i] = 0\n",
    "            else:\n",
    "                s[i] = 1\n",
    "            \n",
    "            if s[i] == 0:\n",
    "                count[joined] += 1\n",
    "                #increment(count, joined)\n",
    "                t += 1\n",
    "            else:\n",
    "                count[prev_word] += 1\n",
    "                count[next_word] += 1\n",
    "                #increment(count, prev_word)\n",
    "                #increment(count, next_word)\n",
    "                t += 2\n",
    "\n",
    "            opsa_progress_bar.update(1)\n",
    "        \n",
    "    words_updated = segmentation(text, text_size, s)\n",
    "    now = \" \".join(words_updated)\n",
    "    with open('data/output.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e4b3fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "alpha = 100\n",
    "p_c = 0.5\n",
    "p_cont = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "aea53ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2f11f7b53645a8984e58530c52af93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text processing:   0%|          | 0/652295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ba0ac901174bb780dfb6798757223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CRP_TextSegmentation(text, text_size, iterations, alpha, p_c, p_cont)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
