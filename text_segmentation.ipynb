{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad156f9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265dd22",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9181a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TributespouredinfromaroundtheworldThursdaytothelateLabourPartyleaderJohnSmith,whodiedearlierfromamassiveheartattackaged55.InWashington,theUSStateDepartmentissuedastatementregretting\"theuntimelydeath\"oftherapier-tonguedScottishbarristerandparliamentarian.\"Mr.Smith,throughouthisdistinguishedcareeringovernmentandinopposition,leftaprofoundimpressiononthehistoryofhispartyandhiscountry,\"StateDepartmentspokesmanMichaelMcCurrysaid.\"Secretary(ofStateWarren)ChristopherextendshisdeepestcondolencestoMrs.SmithandtotheSmithchildren.\"InBonn,theheadoftheGermanSocialDemocraticParty,RudolfScharping,saidinastatementhewas\"veryaffectedbythesuddendeathofJohnSmith.\"AgoodfriendofGermansocialdemocracyhasleftustooearly.Hewasveryclosetoachievinghislife'sgoalofmakingtheLabourPartythelargestpoliticalforceinBritain\"andwouldbe\"cruellymissed\"inEurope,hesaid.HongKongGovernorChrisPatten,aformerConservativePartychairman,offeredhiscondolencestotheSmithfamilyandsaidhisformerpolitcalopponentwasa\"goodanddecentman,widelyresp\n"
     ]
    }
   ],
   "source": [
    "with open('text_seg/data_small.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7344e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652297"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_size = len(text)\n",
    "text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a6e917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = len(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c3df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 74\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique characters: {}\".format(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d8729",
   "metadata": {},
   "source": [
    "- There is 2 𝑛−1 possible segmentations for 𝑛-characters long data.\n",
    "- 𝑛 − 1 latent binary variables $𝑠_𝑖$: denoting whether there is of isn’t a separator between two characters.\n",
    "- Collapsed Gibbs sampling. Sample one variable conditioned by all the others.\n",
    "- Exchangeability: if we reorder the words in the sequence, overall probability is the same.\n",
    "- We can virtually move the changed words at the end of the sequence, compute the overal probablility of the two possibilities and then move the words virtually back.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb53741b",
   "metadata": {},
   "source": [
    "if $s_i$ is 1, then there is a separator between characters $c_i$ and $c_{i+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b6384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the random seeds\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c569a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def segmentation(text, text_size, s):\n",
    "    words = []\n",
    "    current_word = \"\"\n",
    "    for idx, character in enumerate(text):\n",
    "        if idx == text_size - 1:\n",
    "            current_word += character\n",
    "            continue\n",
    "        \n",
    "        if s[idx] == 1:\n",
    "            current_word += character\n",
    "            words.append(current_word)\n",
    "            current_word = \"\"\n",
    "        else:\n",
    "            current_word += character\n",
    "    return words\n",
    "\n",
    "def get_word_counts(words):\n",
    "    count = {}\n",
    "    counter = collections.Counter(words)\n",
    "    return counter\n",
    "    for key, value in counter.items():\n",
    "        count[key] = value\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e93bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_word(text, s, i):\n",
    "    word = \"\"\n",
    "    start_idx = i - 1\n",
    "    if s[start_idx] == 1:\n",
    "        start_idx -= 1\n",
    "    while start_idx >= 0:\n",
    "        if s[start_idx] == 1:\n",
    "            break\n",
    "        start_idx -= 1\n",
    "    \n",
    "    word = text[start_idx+1:i]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230a51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(text, s, i):\n",
    "    word = \"\"\n",
    "    end_idx = i + 1\n",
    "    while end_idx < len(text) - 1:\n",
    "        if s[end_idx] == 1:\n",
    "            break\n",
    "        end_idx += 1\n",
    "    \n",
    "    word = text[i:end_idx + 1]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3f013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p0(word, p_c):\n",
    "    uniform = 1.0 / float(C)\n",
    "    return uniform**len(word) * p_c**(len(word)-1) * (1 - p_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e31103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(count_dict, word):\n",
    "    if word not in count_dict:\n",
    "        count_dict[word] = 0\n",
    "    \n",
    "    count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ba35ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrement(count_dict, word):\n",
    "    if word not in count_dict:\n",
    "        count_dict[word] = 1\n",
    "    \n",
    "    count_dict[word] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "249a2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRP_TextSegmentation(text, text_size, iterations, alpha, p_c, p_cont, T = 1, T_decrease = 1, T_decrease_frequency = 10):\n",
    "    s = np.random.randint(low=0, high=2, size=text_size-1)\n",
    "    words = segmentation(text, text_size, s)\n",
    "    count = get_word_counts(words)\n",
    "    t = sum(count.values())\n",
    "    \n",
    "    opsa_progress_bar = tqdm(range(1, text_size - 1), desc=\"Text processing\")\n",
    "    \n",
    "    for iteration in tqdm(range(iterations), desc=\"Iterations\"):\n",
    "        opsa_progress_bar.reset()\n",
    "        for i in np.random.permutation(range(1, text_size - 1)):\n",
    "            \n",
    "            prev_word = get_prev_word(text, s, i)\n",
    "            next_word = get_next_word(text, s, i)\n",
    "            \n",
    "            joined = prev_word + next_word\n",
    "            if s[i] == 0:\n",
    "                count[joined] = max(0, count[joined] - 1)\n",
    "                t -= 1\n",
    "            else:\n",
    "                count[prev_word] = max(0, count[prev_word] - 1)\n",
    "                count[next_word] = max(0, count[next_word] - 1)\n",
    "                t -= 2\n",
    "            \n",
    "            p_0 = (alpha * p0(joined, p_c) + count[joined]) / (alpha + t)\n",
    "            p_1 = (alpha * p0(prev_word, p_c) + count[prev_word]) / (alpha + t)\n",
    "            p_1 *= (alpha * p0(next_word, p_c) + count[next_word]) / (alpha + t + 1)\n",
    "            p_1 *= p_cont\n",
    "            \n",
    "            # Annealing\n",
    "            if i % T_decrease_frequency == 0 and T > 0:\n",
    "                p_0 = p_0 ** (1/T)\n",
    "                p_1 = p_1 ** (1/T)\n",
    "            \n",
    "            #s[i] = sample 0 or 1 with weights p[0] and p[1]\n",
    "            \n",
    "            # Doesn't work because probabilities do not sum up to 1.00\n",
    "            #s[i] = np.random.choice([0, 1], p=[p_0, p_1])\n",
    "            if (random.random() * (p_0 + p_1)) < p_1:\n",
    "                s[i] = 0\n",
    "            else:\n",
    "                s[i] = 1\n",
    "            \n",
    "            if s[i] == 0:\n",
    "                count[joined] += 1\n",
    "                t += 1\n",
    "            else:\n",
    "                count[prev_word] += 1\n",
    "                count[next_word] += 1\n",
    "                t += 2\n",
    "\n",
    "            opsa_progress_bar.update(1)\n",
    "        \n",
    "    words_updated = segmentation(text, text_size, s)\n",
    "    final_output = \" \".join(words_updated)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PitmanYorTextSegmentation(text, text_size, iterations, alpha, p_c, p_cont, T = 1, T_decrease = 1, T_decrease_frequency = 10):\n",
    "    s = np.random.randint(low=0, high=2, size=text_size-1)\n",
    "    words = segmentation(text, text_size, s)\n",
    "    count = get_word_counts(words)\n",
    "    t = sum(count.values())\n",
    "    \n",
    "    opsa_progress_bar = tqdm(range(1, text_size - 1), desc=\"Text processing\")\n",
    "    \n",
    "    for iteration in tqdm(range(iterations), desc=\"Iterations\"):\n",
    "        opsa_progress_bar.reset()\n",
    "        for i in np.random.permutation(range(1, text_size - 1)):\n",
    "            \n",
    "            prev_word = get_prev_word(text, s, i)\n",
    "            next_word = get_next_word(text, s, i)\n",
    "            \n",
    "            joined = prev_word + next_word\n",
    "            if s[i] == 0:\n",
    "                count[joined] = max(0, count[joined] - 1)\n",
    "                t -= 1\n",
    "            else:\n",
    "                count[prev_word] = max(0, count[prev_word] - 1)\n",
    "                count[next_word] = max(0, count[next_word] - 1)\n",
    "                t -= 2\n",
    "            \n",
    "            p_0 = (alpha * p0(joined, p_c) + count[joined]) / (alpha + t)\n",
    "            p_1 = (alpha * p0(prev_word, p_c) + count[prev_word]) / (alpha + t)\n",
    "            p_1 *= (alpha * p0(next_word, p_c) + count[next_word]) / (alpha + t + 1)\n",
    "            p_1 *= p_cont\n",
    "            \n",
    "            # Annealing\n",
    "            if i % T_decrease_frequency == 0 and T > 0:\n",
    "                p_0 = p_0 ** (1/T)\n",
    "                p_1 = p_1 ** (1/T)\n",
    "            \n",
    "            #s[i] = sample 0 or 1 with weights p[0] and p[1]\n",
    "            \n",
    "            # Doesn't work because probabilities do not sum up to 1.00\n",
    "            #s[i] = np.random.choice([0, 1], p=[p_0, p_1])\n",
    "            if (random.random() * (p_0 + p_1)) < p_1:\n",
    "                s[i] = 0\n",
    "            else:\n",
    "                s[i] = 1\n",
    "            \n",
    "            if s[i] == 0:\n",
    "                count[joined] += 1\n",
    "                t += 1\n",
    "            else:\n",
    "                count[prev_word] += 1\n",
    "                count[next_word] += 1\n",
    "                t += 2\n",
    "\n",
    "            opsa_progress_bar.update(1)\n",
    "        \n",
    "    words_updated = segmentation(text, text_size, s)\n",
    "    final_output = \" \".join(words_updated)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4b3fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "alpha = 100\n",
    "p_c = 0.5\n",
    "p_cont = 0.99\n",
    "T = 1\n",
    "T_decrease = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea53ec5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f0524322504446b734d038381b5df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text processing:   0%|          | 0/652295 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e09f79e80448cf876776261e003143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = CRP_TextSegmentation(text, text_size, iterations, alpha, p_c, p_cont, T, T_decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af246c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T rib ut es pour edinfro ma roundth eworld Th ursd a ytot h ela te La b our P a rty le ad erJohnS m ith,wh odi edearlier fr om ama ssi ve heartat t ackag e d55. I nW as hi ng ton, theUS St a teD epa r tme n t iss uedasta tementre gre tt i ng\"th eu ntimel y dea t h\"ofth erapi er -ton gue dS cot ti shbarri sterandp ar liamen ta rian.\" M r.Sm it h,t hr oug hou this disti ngui s hedca reeri n go v e rnm entandin o p po s i ti on , leftap r ofo un dimpres si o no nth eh isto ryofhi sp artyan dh iscountr y, \"Sta teDe p a rt mentsp ok es m anMi c haelMc Cu rrysa id .\" Sec ret ary( ofS t a te W a rre n) Ch ristopher ex t endshi sd eepest co ndo len ce st oMrs .Smi thand tothe S mit hchild ren .\" InBon n ,thehe ad o ft h eG erm an Soc ialDe m oc raticPa rty,R ud ol fSc harpi ng ,s aidinast ate menthe wa s \" ve ry affe c t ed by t he s udde nd ea th of Joh nS mi th .\"A go odfri end ofGer ma n sociald em o c r ac y hasl ef tu s to oe ar ly. Hew a s v e ryc los etoa ch ie vi n g hi slife \\'sg o alo fm ak ingtheLabou rP a rtythe la rgestp ol i tic a l for c einBri ta in\"an dwoul db e \"cru el lymi ss ed \"inE ur o pe,h esa i d. Hong K o ng G ove rno rChris Pa tten, afo rm er C o nse rva ti vePa rty c h air ma n, offere dhi scon do le ncestoth eS mit hfa mi lyandsa id hisformerp ol itcalop p o nen twasa \"gooda nddecen tman,w id ely respec te d. \"I nFranc e,F ren c h Pre si d en tFr an co isM it te rran dse n tamessa geof co nd ole ncestoS mith\\' s wido wE li zabe tha n d to La b o urP a rt yge neral-se cr et ar yL a rryW hi tt y.T heheado fth eFr enchSociali stP arty M ichel Roca rdto ldFr en chra dio Thu rs d a y hewa s\"sh oc ke d a nd stunne d\" by Sm it h\\'sd eath:R oc ar dhad sp ent We dne sdayeven ing wi t hSm it h an dhisw if eafterat tendin gth elaunchin L ond on oftheL abourPar tyca mpa ig nf ortheE ur ope an ele c tio ns.\"He wasin grea tsh apelas tn ig ht, andthis camea sa shoc k tome, \"R oca r d sai d.\"J oh nSmith was afer van tEur opea n.H efough tf oraGr eat Bri t ain th at'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402af73",
   "metadata": {},
   "source": [
    "Method that saves the output of the segmentation and calls the Perl script for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982fd21",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "**Download the gold data and the evaluation script. What precision and recall you get?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c34603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_evaluate(output_file_path):\n",
    "    output_file_path = \"text_seg/\" + output_file_path\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(output)\n",
    "    !perl text_seg/eval.pl text_seg/data_small_gold.txt $output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "209fc018",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:0.023, R:0.039, F:0.029\n"
     ]
    }
   ],
   "source": [
    "output_file_path = \"run_1_basic.txt\"\n",
    "save_and_evaluate(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
